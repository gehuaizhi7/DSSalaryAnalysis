--- 
title: "DSSalaryAnalysis"
author: "Huaizhi Ge, Huanyu Jiang and Binghong Yu"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---
--- 
title: "DSSalaryAnalysis"
author: "Huaizhi Ge, Huanyu Jiang and Binghong Yu"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---
```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  cache.lazy = FALSE
)
```



# Introduction

We choose this topic because data science is our shared major. Over the last ten years, data science has progressed considerably. Data science is an enthralling, lucrative, and rapidly expanding discipline. Data scientists organize and analyze enormous amounts of information, look for trends, and make predictions. Data science majored students are required in nearly every field, including business, finance, science, health, and government. As students who are looking for a position in job market, the first thing concerning us is the salary of a job position. As a data science student, we are interested in learning the salary patterns in different data science positions. We do so with the techniques we learned in class. 

<!--chapter:end:index.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  cache.lazy = FALSE
)
```
# Data sources

## data link: https://github.com/picklesueat/data_jobs_data

The data was collected from Glassdoor, an anonymous review service for current and past employees in the United States. On Glassdoor, users may anonymously post and view salaries, as well as search for and apply for jobs. Binghong Yu was responsible for collecting the data. We tried to scrap the website. however the api provided by Glassdoor was taken down and no longer available to the public. As a result, we failed to scrap the website. But we found the scraped data from GitHub, and downloaded it. 


The dataset is created by picklesueat from Glassdoor. This repo contains four files, including: BusinessAnalyst.csv (4092 * 15), DataAnalyst.csv (5631 * 15), DataEngineer.csv (2528 * 15), and DataScientist.csv (3909 * 15).Each gives information about a branch of data related jobs. For each of them, there are 15 features: 'Job Title', 'Salary Estimate', 'Job Description', 'Rating', 'Company Name', Location', 'Headquarters', 'Size', 'Founded', 'Type of ownership', 'Industry', Sector', 'Revenue', 'Competitors', 'Easy Apply’.
There were a few problems with the raw dataset, and we cleaned it so that it could giver much more clear information for the further analysis. 

First of all, the value of salary feature contains words “GlassDoor estimated”. We only want the actual number of salary, so we deleted the words contained in the salary column and replaced "k", representing thousands, as "1,000".

Secondly, we modified job titles. For example, some of the job titles contains key words "Jr" and "Sr" while others uses "Junior" and "Senior". To make the data make more sense, we modified them to have the same representation. We made them follow a certain pattern to give a more clear information. 

Thirdly, we modified number of employer. For some of the data, number of employers was represented by a range, while others were represented by a specific number. This made the analysis more complicated. We take mean of the range and let the mean to be the new value of this feature

<!--chapter:end:02-data.Rmd-->


# Data transformation

Placeholder



<!--chapter:end:03-cleaning.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  cache.lazy = FALSE
)
```
# Missing values 



```{r echo=FALSE}
# Basics
if(!require(dplyr)) install.packages("dplyr")
if(!require(tibble)) install.packages("tibble")
if(!require(tidyr)) install.packages("tidyr")
if(!require(ggplot2)) install.packages("ggplot2")
if(!require(forcats)) install.packages("forcats")
if(!require(patchwork)) install.packages("patchwork")
if(!require(scales)) install.packages("scales")
if(!require(readr)) install.packages("readr")
if(!require(ggthemes)) install.packages("ggthemes")
if(!require(ggrepel)) install.packages("ggrepel")
if(!require(GGally)) install.packages("GGally")
if(!require(plotly)) install.packages("plotly")
if(!require(forcats)) install.packages("forcats")
if(!require(stringr)) install.packages("stringr")

if(!require(ggpubr)) install.packages("ggpubr")
if(!require(PupillometryR)) install.packages("PupillometryR")
if(!require(ggridges)) install.packages("ggridges")
if(!require(RColorBrewer)) install.packages("RColorBrewer")
if(!require(magrittr)) install.packages("magrittr") # allow %<>%

if(!require(vcd)) install.packages("vcd")
if(!require(d3r)) install.packages("d3r")
if(!require(ggalluvial)) install.packages("ggalluvial")
if(!require(parcoords)) install.packages("parcoords")

# pair plot
if(!require(gridGraphics)) install.packages("gridGraphics")
if(!require(gridExtra)) install.packages("gridExtra")
library("data.table")
library("readxl")
library(mi)
```



```{r echo=FALSE}
ds_data <- read_excel("data/clean_loc.xlsx")

```

## missing value by column:

```{r echo=FALSE}
colSums(is.na(ds_data)) %>%
  sort(decreasing = TRUE)
```
For each columns, their number of missing values are show below. As we can see from the form, most of the values under “easy apply” and “competitor” labels are missing. That means we should avoid to investigate the relation of salary and these two features. 
Among all features, “Sectors”, “Industry”, and “number of employees” are least missing values. Thus, we want to investigate more about relations of these features and salary level. 


## display first ten company 

```{r echo=FALSE, fig.width = 13}
n_row = nrow(ds_data)
variables = colnames(ds_data)

ds_data %>% 
  slice(1:10) %>%
  mutate_all( as.character) %>%
  relocate(`Name of Company`, 1) %>%
  pivot_longer(2:ncol(.)) %>%
  mutate(missing = ifelse(is.na(value), T, F)) %>%

ggplot() +
  geom_tile(aes(x=name,
                y=`Name of Company`,
                fill=factor(missing))) + 
  labs(x = 'variable', y = 'company')+
  scale_fill_manual(values = c("grey60", alpha( "cornflowerblue", 0.6))) +
  scale_alpha_manual(values = c(0.5, 0.9)) +
  theme(axis.text.x = element_text(angle = 20,hjust = 0.95,vjust = 0.95))
```
The following missing pattern graph shows the pattern of missing values. Blue represents data that are missing, while gray represents data that are not missing. We can find out from the map that “revenue”, “competitors”, and “year founded”  have most missing value in the dataset. Besides this, we also find out that there is no correlation between features that are missing, that is, no feature leads to other features’ data missing. Therefore, we can investigate each feature without being intervened by other feature’s missing data.

## use mi library draw heatmap and check missing value

```{r echo=FALSE, fig.height=6}
x <- mi::missing_data.frame(ds_data %>% as.data.frame())
image(x)
```

This table displays 63 missing patterns.
```{r echo=FALSE}
levels(x@patterns)
```

This table displays missing patterns and how many time it appears.
```{r echo=FALSE}
summary(x@patterns)
```


```{r echo=FALSE, fig.height= 8, fig.width= 10}
missing_value_plot <- function(df, showcount=TRUE){
  
  missing_patterns <- data.frame(is.na(df)) %>%
  group_by_all() %>%
  count(name = "count", sort = TRUE) %>%
  ungroup()
  n_row =  nrow(df)
  colname = colnames(df)

  up_table <- missing_patterns %>% 
      pivot_longer(-c(count), 
                   names_to = "var",
                   values_to = "missing") %>% 
      mutate(temp = missing * count) %>%
      group_by(var) %>%
      summarise(total_row = sum(temp)) %>% 
      arrange(-total_row) %>% 
      mutate(percent_row = total_row/n_row*100,var = fct_inorder(var))
  
  if(showcount){
    up_table %>%
    ggplot(aes(x = var ,y = total_row))+
    geom_col(show.legend = FALSE,fill="#4D65D0")+
    labs(x="",y="num rows missing") +
    scale_y_continuous(expand = c(0,0))+
    theme(axis.text.x = element_text(angle = 20,hjust = 0.95,vjust = 0.95))  -> p1
    
  }else{
    up_table %>%
    ggplot(aes(x = var ,y = percent_row))+
    geom_col(show.legend = FALSE,fill="#4D65D0")+
    labs(x="",y="% rows missing") +
    scale_y_continuous(expand = c(0,0),limits = c(0,100))+
    theme(axis.text.x = element_text(angle = 20,hjust = 0.95,vjust = 0.95)) -> p1
  }

  var_seq = levels(fct_inorder(up_table$var))
  
  missing_patterns %>% 
      arrange(-count) %>%
      mutate(index = factor(1:n()),
             percent_pat = count/n_row*100) ->  temp_1
      temp_1 %>% select_at(var_seq) %>%
      apply(1, sum) -> missing_sum
  
      temp_1 %>%
      mutate(missing_sum = missing_sum,
           complete_cases = ifelse(missing_sum == 0, T,F))   %>% 
      select(c(index,percent_pat,count,complete_cases)) -> right_table
  
  if(showcount){
    right_table %>%
    ggplot(aes(x = count,y = fct_rev(index),fill=complete_cases))+
    geom_col(show.legend = FALSE)+
    scale_fill_manual(values = c("#4D65D0", "#2A22FF")) +
    labs(x="row count",y="")+
    scale_x_continuous(expand = c(0,0)) +
    theme(axis.text.x = element_text(angle = 20,hjust = 0.95,vjust = 0.95))-> p2
    
  }else{
    right_table %>%
    ggplot(aes(x = percent_pat,y = fct_rev(index),fill=complete_cases))+
    geom_col(show.legend = FALSE)+
    scale_fill_manual(values = c("#4D65D0", "#2A22FF")) +
    labs(x="% rows",y="")+
    scale_x_continuous(expand = c(0,0),limits = c(0,100)) +
    theme(axis.text.x = element_text(angle = 20,hjust = 0.95,vjust = 0.95)) -> p2 }
    
  central_table <- missing_patterns %>% 
      arrange(-count) %>%
      select_at(var_seq) %>% 
      mutate(index = factor(1:n())) ->  temp_2
      temp_2 %>% select_at(var_seq) %>%
      apply(1, sum) -> missing_sum_1
  
    central_table <- temp_2 %>%
      mutate(missing_sum_1 = missing_sum_1,
           complete_cases = ifelse(missing_sum_1 == 0, T,F))   %>% 
      pivot_longer(-c(index,complete_cases,missing_sum_1),names_to = "var", values_to = "missing") %>%
      rename(feature = var) %>%
      mutate(feature = factor(feature, levels = var_seq))
 
  n = ceiling((length(var_seq))/2)

  tibble(index = central_table %>% filter(complete_cases) %>% distinct(index) %>% pull(index),
         feature = var_seq[n],
         label = "complete cases") -> text
  
  
  central_table %>% 
    
    ggplot() +
    geom_tile(aes(x=feature,y=fct_rev(index),fill=factor(missing),alpha=complete_cases),
              color = "white",show.legend = FALSE) + 
    geom_text(data = text,
              aes(x = feature, 
                  y = index,
                  label = label),
              size = 6,
              color = "black",
              na.rm = TRUE)  +
    labs(x = 'variable', y = 'missing pattern')+
    scale_fill_manual(values = c("grey40", "purple")) +
    scale_alpha_manual(values = c(0.5, 0.9)) +
    theme(axis.text.x = element_text(angle = 20,hjust = 0.95,vjust = 0.95))-> p3
    
 layout<- "111111144
  111111144
  333333322
  333333322
  333333322
  333333322
  333333322
  333333322
  333333322"
  print(p1+p2+p3 + plot_layout(design = layout))
}

```

## Missing pattern plot 

### display with percentage
```{r echo=FALSE, fig.width=17,fig.height=10}
missing_value_plot(ds_data,showcount = F)
```

### display with count number
```{r echo=FALSE, fig.width=17,fig.height=10}
missing_value_plot(ds_data,showcount = T)
```

The most frequent missing pattern is the pattern where 'Easy.apply' and 'Competitors' are both missing, while the other variables are not. Moreover, 'Easy.apply' and 'Competitors' are more likely to be missing in the dataset than the other variables. 
While other values are missing, the values of Company.name, index, Job.Description, Job.Title, Location, Salary.Estimate, and X are all presenting in the dataset. 

The features Industry and Sector seem to be missing at the same time. 

The feature Founded seems to be an independent feature, its representing doesn't effect other feature’s status. 

Complete cases only appears less than 100 rows while there are more than 2000 rows of data in the set.

<!--chapter:end:04-missing.Rmd-->


# Results

Placeholder


## wordcloud for skillset
### Box plot for skillset vs salary
## salary vs job title 
## Education level vs salary
## Ridge line plot for sector vs salary
## Hex plot for founded year vs salary hex plot
## Cleveland dot plot for Company vs salary
## Glassdoor rating vs salary, wrap by Industry
## Alluvial plot (Sector, Type of ownership, salary_group) 
## Employee Salary Group VS Company Revenue Level - Mosaic Plot

<!--chapter:end:05-results.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  cache.lazy = FALSE
)
```
# Interactive component


<iframe src="d3.html" width="750" height="550"></iframe>

This interactive component shows the relationship between company location, job title, and salary.

The tool is interactive. There are 4 checkboxes on the graph, representing Data Analytics, Data Scientist, Business Analytics, and Data Engineer. If you check the checkbox which represents a job title, the d3 graph will show some circles. Every circle represents a state in the United States. The position in the map of the circle represents the state location. The radius of the circles represent the salary level. The larger the radius is, the higher the average salary is. By checking the checkbox, you can see the salary of every state intuitively. When you move your mouse to a certain circle, it will show a box under the graph including the information about the state name, job type, count, and average salary.

Data Analytics jobs are widely demanded. Data Scientist, Business Analytics, and Data Engineer job demands are ditributed on the west side as well as the east side. The salary of the Data Scientist is the highest. The salary of the Data Engineer is the second highest. There is little difference bewteen the salary of the Data Analytics and the Business Analytics. And Business Analytics, and Data Engineer jobs are always demanded together.

<!--chapter:end:06-interactive.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  cache.lazy = FALSE
)
```
# Conclusion

There are several limitations on our study. Most of them are data-related. First of all, we use data provided by Glassdoor, a job-finding website where companies and employees post their advertisements and their resumes. This lead to a problem. The data that we collect could be a bit off from the real situation in the industry. For example, a company may put a higher salary amount on their advertisements while the real salaries are lower. And many of their job descriptions are the minimal qualification needed for this job, but they give offers to applicants who are overqualified. That lead to a problem that the status that we examined might be different from the real situation in the industry. Therefore in the future, we want to collect data from more authentic sources. Corporate Annual Report is a good example. All data provided by their reports are authentic and reliable. 
After investigating all possible factors provided in the dataset, now we have a clear clue about what make a job high-paid. First of all, jobs in IT, Media and Biotech industries pay more. Secondly, skill sets largely determine the salary level. Some of the high paid jobs require employees to have a good grip of advanced skills such as R, SQL and Machine Learning. Therefore, as job seekers in data related fields are encouraged to pursue a higher degree and try to comprehend as more skills as possible. 

<!--chapter:end:07-conclusion.Rmd-->

